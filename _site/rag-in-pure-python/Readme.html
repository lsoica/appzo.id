<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>RAG in pure Python</title>
  <link rel="stylesheet" href="/assets/css/style.css">
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      display: flex;
      min-height: 100vh;
      overflow-x: hidden;
    }

    .sidebar {
      width: 200px;
      background-color: #f4f4f4;
      padding: 20px;
      position: fixed;
      height: 100vh;
      top: 0;
      left: 0;
    }

    .content-wrapper {
      margin-left: 220px; /* Ensure space for the sidebar */
      padding: 20px;
      width: calc(100% - 220px); /* Prevent overflow beyond viewport */
      box-sizing: border-box;
    }

    .content {
      max-width: 100%; /* Make sure content doesn't exceed available width */
      padding: 20px;
    }

    .sidebar a {
      display: block;
      padding: 10px 0;
      color: #333;
      text-decoration: none;
    }

    .sidebar a:hover {
      background-color: #ddd;
    }

    .category-list, .post-list {
      margin-top: 20px;
    }
  </style>
</head>
<body>

  <div class="sidebar">
    <h2><a href="">Appzoid</a></h2>
    <a href="/2024/09/23/learning-neural-networks">Learning Neural Nets</a>
    <a href="/2024/07/24/llm-models">Large Language Models</a>
    <a href="/2024/07/24/vision">Computer Vision</a>
    <a href="/2024/08/16/pytorch">PyTorch</a>
    <a href="/2024/08/16/rag">RAG</a>
    <a href="/2024/07/24/backpropagation">Backpropagation</a>
    <a href="/machine-learning-and-deep-learning/readme.html">ML and DL with PyTorch</a>
  </div>

  <div class="content-wrapper">
    <div class="content">
      <h1 id="rag">RAG</h1>

<h2 id="chunking-and-embedding">Chunking and embedding</h2>

<p>A document is chunked first. The strategy could be as simple as splitting on paragraphs (e.g. \n\n).</p>

<p>Then for each chunk a single vector embedding is returned by the model. Because the model is built to compute one embedding for each token, a strategy is required to combine the embeddings of the tokens in each chunk into a single embedding. The simplest approach would be to take the average of all the vectors.</p>

<p>A pooling mechanism is applied to reduce the token-level embeddings into a single vector. This is often done using:</p>
<ul>
  <li>Mean pooling: Averaging the embeddings of all tokens.</li>
  <li>CLS token pooling: Using the special [CLS] token in models like BERT as the aggregate representation of the entire input sequence.</li>
</ul>

<h2 id="querying">Querying</h2>

<p>documents -&gt; chunks -&gt; embedding vector
                                              dot product -&gt; most similar n chunks -&gt; feed the model with the query and the top n paragraphs -&gt; return the results.
 query               -&gt; embedding vector</p>

<p>An embedding is computed for the query string as well, then the query vector is compared to each chunk vector. The closest match(s) are returned and now we know the top n documents that are most similar to the query. We can feed these documents into the model to get the results.</p>

<h2 id="reference">Reference</h2>

<p><a href="https://www.youtube.com/watch?v=bmduzd1oY7U&amp;ab_channel=PromptEngineering">RAG in pure python demo</a></p>

<h2 id="implementation">Implementation</h2>

<div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;">
  <div class="jupyter-notebook-iframe-container">
    <iframe src="rag.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe>
  </div>
</div>

    </div>
  </div>

</body>
</html>
